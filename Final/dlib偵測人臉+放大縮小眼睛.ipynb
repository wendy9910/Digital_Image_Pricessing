{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c097ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2                #影象處理庫OpenCV\n",
    "import dlib               #人臉識別庫dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36075e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_deformation(landmarks,img):\n",
    "    LeyePosCenter = (int((landmarks[36,0]+landmarks[39,0])/2),int((landmarks[36,1]+landmarks[39,1])/2))\n",
    "    ReyePosCenter = (int((landmarks[42,0]+landmarks[45,0])/2),int((landmarks[42,1]+landmarks[45,1])/2))\n",
    "    \n",
    "    Leyepts1 = np.uint32([[landmarks[36,0],landmarks[36,1]],[landmarks[37,0],landmarks[37,1]]\n",
    "                       ,[landmarks[38,0],landmarks[38,1]],[landmarks[39,0],landmarks[39,1]]\n",
    "                       ,[landmarks[40,0],landmarks[40,1]],[landmarks[41,0],landmarks[41,1]]])\n",
    "    \n",
    "    Reyepts1 = np.uint32([[landmarks[42,0],landmarks[42,1]],[landmarks[43,0],landmarks[43,1]]\n",
    "                       ,[landmarks[44,0],landmarks[44,1]],[landmarks[45,0],landmarks[45,1]]\n",
    "                       ,[landmarks[46,0],landmarks[46,1]],[landmarks[47,0],landmarks[47,1]]])\n",
    "    \n",
    "    Leyepts2 = eye_deformation_enlarge_Pos(Leyepts1,LeyePosCenter,move)    \n",
    "    Leyepts = tuple(map(tuple, Leyepts2))\n",
    "    Reyepts2 = eye_deformation_enlarge_Pos(Reyepts1,ReyePosCenter,move)\n",
    "    Reyepts = tuple(map(tuple, Reyepts2))\n",
    "    \n",
    "#     for pos in Leyepts:\n",
    "#         cv2.circle(img, pos, 5, color=(0, 0, 255),thickness = -1)  \n",
    "#     for pos in Reyepts:\n",
    "#         cv2.circle(img, pos, 5, color=(0, 0, 255),thickness = -1)   \n",
    "        \n",
    "    initial = trans(img, Leyepts1)\n",
    "    img2 = initial.deformation(img, Leyepts2)\n",
    "    initial2 = trans(img2, Reyepts1)\n",
    "    img3 = initial2.deformation(img2, Reyepts2)\n",
    "    \n",
    "    return img3\n",
    "\n",
    "#調整頂點位置\n",
    "def eye_deformation_enlarge_Pos(pos1,c,move):\n",
    "    a = np.empty(shape=(0, 2))\n",
    "    #位移方向\n",
    "    for idx, point in enumerate(pos1):\n",
    "        vec1 = np.int32([pos1[idx]-c])   \n",
    "        a = np.append(a,vec1,axis=0)\n",
    "    dic = normalization(a)\n",
    "    p1 = np.empty(shape=(0, 2))\n",
    "    #加移動向量\n",
    "    for idx, point in enumerate(pos1):\n",
    "        pos = np.uint32([pos1[idx]+dic[idx]*enlarge_value])\n",
    "        p1 = np.append(p1,pos,axis=0)\n",
    "        p1 = np.uint32(p1)\n",
    "\n",
    "    return p1\n",
    "\n",
    "#規一化後的範圍是[-1, 1]\n",
    "def normalization(data):\n",
    "    _range = np.max(abs(data))\n",
    "    return data / _range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0bbddb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/hjimce/article/details/46550001(MLS參考)\n",
    "#基於移動最小二乘變形方法\n",
    "\n",
    "class trans():\n",
    "    def __init__(self, img, pi):\n",
    "        width, height = img.shape[:2]\n",
    "        pcth = np.repeat(np.arange(height).reshape(height, 1), [width], axis=1)\n",
    "        pctw = np.repeat(np.arange(width).reshape(width, 1), [height], axis=1).T\n",
    "\n",
    "        self.img_coordinate = np.swapaxes(np.array([pcth, pctw]), 1, 2).T\n",
    "        self.cita = compute_G(self.img_coordinate, pi, height, width)\n",
    "        self.pi = pi\n",
    "        self.W, self.A, self.Z = pre_compute_waz(self.pi, height, width, self.img_coordinate)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def deformation(self, img, qi):\n",
    "\n",
    "        qi = self.pi * 2 - qi\n",
    "        mapxy = np.swapaxes(np.float32(compute_fv(qi, self.W, self.A, self.Z, self.height, self.width, self.cita, self.img_coordinate)), 0, 1)\n",
    "        img = cv2.remap(img, mapxy[:, :, 0], mapxy[:, :, 1], borderMode=cv2.BORDER_WRAP, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eda4c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_compute_waz(pi, height, width, img_coordinate):\n",
    "    # height*width*控制点个数\n",
    "    wi = np.reciprocal(np.power(np.linalg.norm(np.subtract(pi, img_coordinate.reshape(height, width, 1, 2)) + 0.000000001, axis=3),2))\n",
    "\n",
    "    # height*width*2\n",
    "    pstar = np.divide(np.matmul(wi,pi), np.sum(wi, axis=2).reshape(height,width,1))\n",
    "\n",
    "    # height*width*控制点个数*2\n",
    "    phat = np.subtract(pi, pstar.reshape(height, width, 1, 2))\n",
    "\n",
    "    z1 = np.subtract(img_coordinate, pstar)\n",
    "    z2 = np.repeat(np.swapaxes(np.array([z1[:,:,1], -z1[:,:,0]]), 1, 2).T.reshape(height,width,1,2,1), [pi.shape[0]], axis=2)\n",
    "\n",
    "    # height*width*控制点个数*2*1\n",
    "    z1 = np.repeat(z1.reshape(height,width,1,2,1), [pi.shape[0]], axis=2)\n",
    "\n",
    "    # height*width*控制点个数*1*2\n",
    "    s1 = phat.reshape(height,width,pi.shape[0],1,2)\n",
    "    s2 = np.concatenate((s1[:,:,:,:,1], -s1[:,:,:,:,0]), axis=3).reshape(height,width,pi.shape[0],1,2)\n",
    "\n",
    "    a = np.matmul(s1, z1)\n",
    "    b = np.matmul(s1, z2)\n",
    "    c = np.matmul(s2, z1)\n",
    "    d = np.matmul(s2, z2)\n",
    "\n",
    "    # 重构wi形状\n",
    "    ws = np.repeat(wi.reshape(height,width,pi.shape[0],1),[4],axis=3)\n",
    "\n",
    "    # height*width*控制点个数*2*2\n",
    "    A = (ws * np.concatenate((a,b,c,d), axis=3).reshape(height,width,pi.shape[0],4)).reshape(height,width,pi.shape[0],2,2)\n",
    "\n",
    "    return wi, A, z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1785dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fv(qi, W, A, Z, height, width, cita, img_coordinate):   \n",
    "    qstar = np.divide(np.matmul(W,qi), np.sum(W, axis=2).reshape(height,width,1))\n",
    "    qhat = np.subtract(qi, qstar.reshape(height, width, 1, 2)).reshape(height, width, qi.shape[0], 1, 2)\n",
    "    fv_ = np.sum(np.matmul(qhat, A),axis=2)\n",
    "    fv = np.linalg.norm(Z[:,:,0,:,:],axis=2) / (np.linalg.norm(fv_,axis=3)+0.0000000001) * fv_[:,:,0,:] + qstar\n",
    "    fv = (fv - img_coordinate) * cita.reshape(height, width, 1) + img_coordinate\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa4b8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_G(img_coordinate, pi, height, width, thre = 0.7):\n",
    "    max = np.max(pi, 0)\n",
    "    min = np.min(pi, 0)\n",
    "\n",
    "    length = np.max(max - min)\n",
    "\n",
    "    # 计算控制区域中心\n",
    "    # p_ = (max + min) // 2\n",
    "    p_ = np.sum(pi,axis=0) // pi.shape[0]\n",
    "\n",
    "    # 计算控制区域\n",
    "    minx, miny = min - length\n",
    "    maxx, maxy = max + length\n",
    "    minx = minx if minx > 0 else 0\n",
    "    miny = miny if miny > 0 else 0\n",
    "    maxx = maxx if maxx < height else height\n",
    "    maxy = maxy if maxy < width else width\n",
    "\n",
    "    k1 =(p_ - [0,0])[1] / (p_ - [0,0])[0]\n",
    "    k2 =(p_ - [height,0])[1] / (p_ - [height,0])[0]\n",
    "    k4 =(p_ - [0,width])[1] / (p_ - [0,width])[0]\n",
    "    k3 =(p_ - [height, width])[1] / (p_ - [height, width])[0]\n",
    "    k = (np.subtract(p_, img_coordinate)[:, :, 1] / (np.subtract(p_, img_coordinate)[:, :, 0] + 0.000000000001)).reshape(height, width, 1)\n",
    "    k = np.concatenate((img_coordinate, k), axis=2)\n",
    "\n",
    "    k[:,:p_[1],0][(k[:,:p_[1],2] > k1) | (k[:,:p_[1],2] < k2)] = (np.subtract(p_[1], k[:,:,1]) / p_[1]).reshape(height, width, 1)[:,:p_[1],0][(k[:,:p_[1],2] > k1) | (k[:,:p_[1],2] < k2)]\n",
    "    k[:,p_[1]:,0][(k[:,p_[1]:,2] > k3) | (k[:,p_[1]:,2] < k4)] = (np.subtract(k[:,:,1], p_[1]) / (width - p_[1])).reshape(height, width, 1)[:,p_[1]:,0][(k[:,p_[1]:,2] > k3) | (k[:,p_[1]:,2] < k4)]\n",
    "    k[:p_[0],:,0][(k1 >= k[:p_[0],:,2]) & (k[:p_[0],:,2] >= k4)] = (np.subtract(p_[0], k[:,:,0]) / p_[0]).reshape(height, width, 1)[:p_[0],:,0][(k1 >= k[:p_[0],:,2]) & (k[:p_[0],:,2] >= k4)]\n",
    "    k[p_[0]:,:,0][(k3 >= k[p_[0]:,:,2]) & (k[p_[0]:,:,2] >= k2)] = (np.subtract(k[:,:,0], p_[0]) / (height - p_[0])).reshape(height, width, 1)[p_[0]:,:,0][(k3 >= k[p_[0]:,:,2]) & (k[p_[0]:,:,2] >= k2)]\n",
    "\n",
    "    cita = np.exp(-np.power(k[:,:,0] / thre,2))\n",
    "    cita[minx:maxx,miny:maxy] = 1\n",
    "    # 如果不需要局部变形，可以把cita的值全置为1\n",
    "    # cita = 1\n",
    "\n",
    "    return cita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eef3b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入放大縮小的值:6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dlib預測器\n",
    "detector = dlib.get_frontal_face_detector()    #使用dlib庫提供的人臉提取器\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')   #構建特徵提取器\n",
    "\n",
    "global new_img\n",
    "enlarge_value = eval(input(\"輸入放大縮小的值:(建議 -8~8 之間)\"))  #放大縮小的調整 value[-10,10]\n",
    "\n",
    "# cv2讀取影象\n",
    "img = cv2.imread(\"C:/Users/88691/Gigital_Image_Processing/HW/Final/Image/me.jpg\")\n",
    "# 取灰度\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# 人臉數rects\n",
    "rects = detector(img_gray, 0)\n",
    "\n",
    "\n",
    "for i in range(len(rects)):\n",
    "    landmarks = np.matrix([[p.x, p.y] for p in predictor(img,rects[i]).parts()])  #人臉關鍵點識別\n",
    "    for idx, point in enumerate(landmarks):        #enumerate函式遍歷序列中的元素及它們的下標\n",
    "        pos = (point[0, 0], point[0, 1])       \n",
    "#         cv2.circle(img, pos, 5, color=(0, 255, 0),thickness = -1)\n",
    "    #生成新照片\n",
    "    new_img = eye_deformation(landmarks,img) \n",
    "      \n",
    "    \n",
    "cv2.imshow(\"old\", img)\n",
    "cv2.imshow(\"new\", new_img)     \n",
    "cv2.waitKey(0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff551c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
